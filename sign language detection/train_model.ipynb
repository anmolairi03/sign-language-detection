{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c76d8492-8b0b-46bb-96a4-a9892551babe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.9-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.15.0-cp312-cp312-win_amd64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "   ---------------------------------------- 0.0/376.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/376.0 MB 7.5 MB/s eta 0:00:51\n",
      "   ---------------------------------------- 2.9/376.0 MB 8.0 MB/s eta 0:00:47\n",
      "    --------------------------------------- 4.7/376.0 MB 8.1 MB/s eta 0:00:46\n",
      "    --------------------------------------- 7.3/376.0 MB 9.1 MB/s eta 0:00:41\n",
      "    --------------------------------------- 9.2/376.0 MB 9.1 MB/s eta 0:00:41\n",
      "   - -------------------------------------- 11.8/376.0 MB 9.6 MB/s eta 0:00:38\n",
      "   - -------------------------------------- 14.4/376.0 MB 10.1 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 16.8/376.0 MB 10.3 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 19.1/376.0 MB 10.3 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 21.2/376.0 MB 10.3 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 23.9/376.0 MB 10.5 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 26.5/376.0 MB 10.6 MB/s eta 0:00:34\n",
      "   --- ------------------------------------ 28.6/376.0 MB 10.6 MB/s eta 0:00:33\n",
      "   --- ------------------------------------ 30.7/376.0 MB 10.5 MB/s eta 0:00:33\n",
      "   --- ------------------------------------ 32.8/376.0 MB 10.5 MB/s eta 0:00:33\n",
      "   --- ------------------------------------ 34.3/376.0 MB 10.2 MB/s eta 0:00:34\n",
      "   --- ------------------------------------ 35.9/376.0 MB 10.1 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 38.0/376.0 MB 10.1 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 40.1/376.0 MB 10.0 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 41.9/376.0 MB 10.0 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 44.0/376.0 MB 10.0 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 46.4/376.0 MB 10.0 MB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 48.8/376.0 MB 10.0 MB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 51.1/376.0 MB 10.1 MB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 53.2/376.0 MB 10.1 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 55.8/376.0 MB 10.2 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 57.9/376.0 MB 10.2 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 60.0/376.0 MB 10.2 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 62.4/376.0 MB 10.2 MB/s eta 0:00:31\n",
      "   ------ --------------------------------- 64.7/376.0 MB 10.2 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 67.1/376.0 MB 10.2 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 69.2/376.0 MB 10.2 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 71.8/376.0 MB 10.3 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 73.9/376.0 MB 10.3 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 76.5/376.0 MB 10.3 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 78.9/376.0 MB 10.4 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 81.3/376.0 MB 10.4 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 83.6/376.0 MB 10.4 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 86.0/376.0 MB 10.4 MB/s eta 0:00:28\n",
      "   --------- ------------------------------ 88.6/376.0 MB 10.5 MB/s eta 0:00:28\n",
      "   --------- ------------------------------ 90.7/376.0 MB 10.5 MB/s eta 0:00:28\n",
      "   --------- ------------------------------ 93.1/376.0 MB 10.5 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 95.4/376.0 MB 10.5 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 98.0/376.0 MB 10.5 MB/s eta 0:00:27\n",
      "   ---------- ---------------------------- 100.7/376.0 MB 10.5 MB/s eta 0:00:27\n",
      "   ---------- ---------------------------- 103.0/376.0 MB 10.6 MB/s eta 0:00:26\n",
      "   ---------- ---------------------------- 105.9/376.0 MB 10.6 MB/s eta 0:00:26\n",
      "   ----------- --------------------------- 108.3/376.0 MB 10.7 MB/s eta 0:00:26\n",
      "   ----------- --------------------------- 110.9/376.0 MB 10.7 MB/s eta 0:00:25\n",
      "   ----------- --------------------------- 113.5/376.0 MB 10.7 MB/s eta 0:00:25\n",
      "   ------------ -------------------------- 116.1/376.0 MB 10.7 MB/s eta 0:00:25\n",
      "   ------------ -------------------------- 118.8/376.0 MB 10.7 MB/s eta 0:00:24\n",
      "   ------------ -------------------------- 121.4/376.0 MB 10.8 MB/s eta 0:00:24\n",
      "   ------------ -------------------------- 124.0/376.0 MB 10.8 MB/s eta 0:00:24\n",
      "   ------------- ------------------------- 126.4/376.0 MB 10.8 MB/s eta 0:00:24\n",
      "   ------------- ------------------------- 129.0/376.0 MB 10.9 MB/s eta 0:00:23\n",
      "   ------------- ------------------------- 131.6/376.0 MB 10.9 MB/s eta 0:00:23\n",
      "   ------------- ------------------------- 134.2/376.0 MB 10.9 MB/s eta 0:00:23\n",
      "   -------------- ------------------------ 136.6/376.0 MB 10.9 MB/s eta 0:00:22\n",
      "   -------------- ------------------------ 139.2/376.0 MB 10.9 MB/s eta 0:00:22\n",
      "   -------------- ------------------------ 141.3/376.0 MB 10.9 MB/s eta 0:00:22\n",
      "   -------------- ------------------------ 143.4/376.0 MB 10.9 MB/s eta 0:00:22\n",
      "   --------------- ----------------------- 145.8/376.0 MB 10.9 MB/s eta 0:00:22\n",
      "   --------------- ----------------------- 147.8/376.0 MB 10.9 MB/s eta 0:00:21\n",
      "   --------------- ----------------------- 149.7/376.0 MB 10.9 MB/s eta 0:00:21\n",
      "   --------------- ----------------------- 151.3/376.0 MB 10.8 MB/s eta 0:00:21\n",
      "   --------------- ----------------------- 153.4/376.0 MB 10.8 MB/s eta 0:00:21\n",
      "   ---------------- ---------------------- 155.5/376.0 MB 10.8 MB/s eta 0:00:21\n",
      "   ---------------- ---------------------- 157.0/376.0 MB 10.8 MB/s eta 0:00:21\n",
      "   ---------------- ---------------------- 159.1/376.0 MB 10.7 MB/s eta 0:00:21\n",
      "   ---------------- ---------------------- 161.2/376.0 MB 10.7 MB/s eta 0:00:21\n",
      "   ---------------- ---------------------- 163.3/376.0 MB 10.7 MB/s eta 0:00:20\n",
      "   ----------------- --------------------- 165.4/376.0 MB 10.7 MB/s eta 0:00:20\n",
      "   ----------------- --------------------- 167.5/376.0 MB 10.7 MB/s eta 0:00:20\n",
      "   ----------------- --------------------- 169.6/376.0 MB 10.7 MB/s eta 0:00:20\n",
      "   ----------------- --------------------- 172.2/376.0 MB 10.7 MB/s eta 0:00:20\n",
      "   ------------------ -------------------- 174.6/376.0 MB 10.7 MB/s eta 0:00:19\n",
      "   ------------------ -------------------- 176.7/376.0 MB 10.7 MB/s eta 0:00:19\n",
      "   ------------------ -------------------- 179.0/376.0 MB 10.7 MB/s eta 0:00:19\n",
      "   ------------------ -------------------- 181.4/376.0 MB 10.7 MB/s eta 0:00:19\n",
      "   ------------------ -------------------- 182.7/376.0 MB 10.6 MB/s eta 0:00:19\n",
      "   ------------------- ------------------- 185.3/376.0 MB 10.7 MB/s eta 0:00:18\n",
      "   ------------------- ------------------- 187.4/376.0 MB 10.6 MB/s eta 0:00:18\n",
      "   ------------------- ------------------- 189.3/376.0 MB 10.6 MB/s eta 0:00:18\n",
      "   ------------------- ------------------- 191.6/376.0 MB 10.6 MB/s eta 0:00:18\n",
      "   -------------------- ------------------ 193.7/376.0 MB 10.6 MB/s eta 0:00:18\n",
      "   -------------------- ------------------ 195.8/376.0 MB 10.6 MB/s eta 0:00:17\n",
      "   -------------------- ------------------ 198.4/376.0 MB 10.6 MB/s eta 0:00:17\n",
      "   -------------------- ------------------ 200.5/376.0 MB 10.6 MB/s eta 0:00:17\n",
      "   --------------------- ----------------- 203.2/376.0 MB 10.6 MB/s eta 0:00:17\n",
      "   --------------------- ----------------- 205.5/376.0 MB 10.6 MB/s eta 0:00:17\n",
      "   --------------------- ----------------- 207.9/376.0 MB 10.6 MB/s eta 0:00:16\n",
      "   --------------------- ----------------- 209.7/376.0 MB 10.6 MB/s eta 0:00:16\n",
      "   --------------------- ----------------- 211.6/376.0 MB 10.6 MB/s eta 0:00:16\n",
      "   ---------------------- ---------------- 213.6/376.0 MB 10.6 MB/s eta 0:00:16\n",
      "   ---------------------- ---------------- 215.7/376.0 MB 10.6 MB/s eta 0:00:16\n",
      "   ---------------------- ---------------- 217.8/376.0 MB 10.6 MB/s eta 0:00:15\n",
      "   ---------------------- ---------------- 219.7/376.0 MB 10.6 MB/s eta 0:00:15\n",
      "   ----------------------- --------------- 222.0/376.0 MB 10.6 MB/s eta 0:00:15\n",
      "   ----------------------- --------------- 224.4/376.0 MB 10.6 MB/s eta 0:00:15\n",
      "   ----------------------- --------------- 226.8/376.0 MB 10.6 MB/s eta 0:00:15\n",
      "   ----------------------- --------------- 228.9/376.0 MB 10.6 MB/s eta 0:00:14\n",
      "   ------------------------ -------------- 231.5/376.0 MB 10.6 MB/s eta 0:00:14\n",
      "   ------------------------ -------------- 233.8/376.0 MB 10.6 MB/s eta 0:00:14\n",
      "   ------------------------ -------------- 236.5/376.0 MB 10.6 MB/s eta 0:00:14\n",
      "   ------------------------ -------------- 239.3/376.0 MB 10.6 MB/s eta 0:00:13\n",
      "   ------------------------- ------------- 241.7/376.0 MB 10.7 MB/s eta 0:00:13\n",
      "   ------------------------- ------------- 243.8/376.0 MB 10.7 MB/s eta 0:00:13\n",
      "   ------------------------- ------------- 246.7/376.0 MB 10.7 MB/s eta 0:00:13\n",
      "   ------------------------- ------------- 249.3/376.0 MB 10.7 MB/s eta 0:00:12\n",
      "   -------------------------- ------------ 251.9/376.0 MB 10.7 MB/s eta 0:00:12\n",
      "   -------------------------- ------------ 254.8/376.0 MB 10.7 MB/s eta 0:00:12\n",
      "   -------------------------- ------------ 257.7/376.0 MB 10.8 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 260.0/376.0 MB 10.8 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 262.9/376.0 MB 10.8 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 265.6/376.0 MB 10.8 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 267.9/376.0 MB 10.9 MB/s eta 0:00:10\n",
      "   ---------------------------- ---------- 270.0/376.0 MB 10.9 MB/s eta 0:00:10\n",
      "   ---------------------------- ---------- 272.4/376.0 MB 10.9 MB/s eta 0:00:10\n",
      "   ---------------------------- ---------- 275.5/376.0 MB 10.9 MB/s eta 0:00:10\n",
      "   ---------------------------- ---------- 278.1/376.0 MB 10.9 MB/s eta 0:00:10\n",
      "   ----------------------------- --------- 280.5/376.0 MB 10.9 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 282.9/376.0 MB 10.9 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 285.0/376.0 MB 10.9 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 286.8/376.0 MB 10.9 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 288.6/376.0 MB 10.8 MB/s eta 0:00:09\n",
      "   ------------------------------ -------- 290.7/376.0 MB 10.8 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 292.8/376.0 MB 10.8 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 295.2/376.0 MB 10.8 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 297.5/376.0 MB 10.9 MB/s eta 0:00:08\n",
      "   ------------------------------- ------- 299.9/376.0 MB 10.9 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 302.5/376.0 MB 10.9 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 305.4/376.0 MB 11.0 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 308.3/376.0 MB 11.0 MB/s eta 0:00:07\n",
      "   -------------------------------- ------ 310.9/376.0 MB 11.0 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 313.5/376.0 MB 11.0 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 316.1/376.0 MB 11.0 MB/s eta 0:00:06\n",
      "   --------------------------------- ----- 319.0/376.0 MB 11.0 MB/s eta 0:00:06\n",
      "   --------------------------------- ----- 321.4/376.0 MB 11.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 324.5/376.0 MB 11.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 327.4/376.0 MB 11.1 MB/s eta 0:00:05\n",
      "   ---------------------------------- ---- 330.0/376.0 MB 11.2 MB/s eta 0:00:05\n",
      "   ---------------------------------- ---- 332.7/376.0 MB 11.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 335.8/376.0 MB 11.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 338.4/376.0 MB 11.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 341.3/376.0 MB 11.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 344.2/376.0 MB 11.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 346.0/376.0 MB 11.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 348.7/376.0 MB 11.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 351.3/376.0 MB 11.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 353.4/376.0 MB 11.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 356.0/376.0 MB 11.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 358.1/376.0 MB 11.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 360.4/376.0 MB 11.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 363.1/376.0 MB 11.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 365.4/376.0 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  367.8/376.0 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  369.9/376.0 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  371.7/376.0 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  373.3/376.0 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.1/376.0 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------- 376.0/376.0 MB 10.7 MB/s eta 0:00:00\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 1.8/4.3 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.9/4.3 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 9.5 MB/s eta 0:00:00\n",
      "Downloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 8.6 MB/s eta 0:00:00\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.9-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp312-cp312-win_amd64.whl (307 kB)\n",
      "Installing collected packages: namex, libclang, termcolor, tensorboard-data-server, optree, grpcio, google-pasta, gast, astunparse, tensorboard, keras, tensorflow\n",
      "Successfully installed astunparse-1.6.3 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 keras-3.9.2 libclang-18.1.1 namex-0.0.9 optree-0.15.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b82ef54-e98e-4a8b-ab6a-12d2f8bc3daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "046a26a3-830b-495f-8226-894663a43cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('X_data.npy')\n",
    "y = np.load('y_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "927d5e7e-0f6b-4b7e-950f-fc1fb03702d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4675446d-f3df-41cb-8fc4-650f6b2a9dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(30, 42), return_sequences=True),\n",
    "    Dropout(0.3),  # Drop 30% of units\n",
    "    LSTM(64),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4115750b-a06c-42c7-875d-4c9962ee5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1e393b6-e90d-4ac1-a062-208d61aaf2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 386ms/step - accuracy: 0.5000 - loss: 0.7105 - val_accuracy: 0.5000 - val_loss: 0.7033\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5000 - loss: 0.6733 - val_accuracy: 0.5000 - val_loss: 0.6968\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5000 - loss: 0.6912 - val_accuracy: 0.5000 - val_loss: 0.7044\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.2500 - loss: 0.6996 - val_accuracy: 0.5000 - val_loss: 0.7099\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.1667 - loss: 0.7454 - val_accuracy: 0.5000 - val_loss: 0.7069\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5000 - loss: 0.6942 - val_accuracy: 0.5000 - val_loss: 0.7102\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6667 - loss: 0.6994 - val_accuracy: 0.5000 - val_loss: 0.7109\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6667 - loss: 0.6488 - val_accuracy: 0.0000e+00 - val_loss: 0.7079\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6667 - loss: 0.6772 - val_accuracy: 0.5000 - val_loss: 0.7078\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9167 - loss: 0.6395 - val_accuracy: 0.5000 - val_loss: 0.7143\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5000 - loss: 0.6679 - val_accuracy: 0.5000 - val_loss: 0.7154\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5833 - loss: 0.6384 - val_accuracy: 0.5000 - val_loss: 0.7155\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7500 - loss: 0.6384 - val_accuracy: 0.5000 - val_loss: 0.7259\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6667 - loss: 0.6424 - val_accuracy: 0.5000 - val_loss: 0.7186\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5833 - loss: 0.6415 - val_accuracy: 0.5000 - val_loss: 0.7143\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6667 - loss: 0.6556 - val_accuracy: 0.5000 - val_loss: 0.7052\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.8333 - loss: 0.5705 - val_accuracy: 0.5000 - val_loss: 0.7220\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5833 - loss: 0.6550 - val_accuracy: 0.5000 - val_loss: 0.7091\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5000 - loss: 0.7233 - val_accuracy: 0.5000 - val_loss: 0.6938\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6667 - loss: 0.5894 - val_accuracy: 0.5000 - val_loss: 0.7009\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4167 - loss: 0.7282 - val_accuracy: 0.5000 - val_loss: 0.7173\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6667 - loss: 0.6075 - val_accuracy: 0.5000 - val_loss: 0.6875\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9167 - loss: 0.5422 - val_accuracy: 0.5000 - val_loss: 0.6860\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7500 - loss: 0.6228 - val_accuracy: 1.0000 - val_loss: 0.6749\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9167 - loss: 0.5774 - val_accuracy: 0.5000 - val_loss: 0.7670\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9167 - loss: 0.4405 - val_accuracy: 0.5000 - val_loss: 0.8710\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5833 - loss: 0.6316 - val_accuracy: 0.5000 - val_loss: 0.9695\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9167 - loss: 0.4263 - val_accuracy: 0.5000 - val_loss: 1.0746\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6667 - loss: 0.6559 - val_accuracy: 0.5000 - val_loss: 0.7887\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8333 - loss: 0.3978 - val_accuracy: 0.5000 - val_loss: 0.8216\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.2803 - val_accuracy: 0.5000 - val_loss: 1.0331\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9167 - loss: 0.3069 - val_accuracy: 0.5000 - val_loss: 1.1535\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9167 - loss: 0.3447 - val_accuracy: 0.5000 - val_loss: 0.9244\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0990 - val_accuracy: 0.5000 - val_loss: 1.2281\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6667 - loss: 0.4862 - val_accuracy: 0.5000 - val_loss: 1.1186\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8333 - loss: 0.3020 - val_accuracy: 0.5000 - val_loss: 0.9548\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.1382 - val_accuracy: 1.0000 - val_loss: 0.3236\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9167 - loss: 0.1716 - val_accuracy: 1.0000 - val_loss: 0.2053\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.1503 - val_accuracy: 0.5000 - val_loss: 1.3899\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.1483 - val_accuracy: 0.5000 - val_loss: 1.2082\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0375 - val_accuracy: 1.0000 - val_loss: 0.0712\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0414 - val_accuracy: 1.0000 - val_loss: 0.0278\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0238 - val_accuracy: 1.0000 - val_loss: 0.0255\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0238 - val_accuracy: 1.0000 - val_loss: 0.0264\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0483 - val_accuracy: 1.0000 - val_loss: 0.0148\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 1.0000 - val_loss: 0.0120\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0245 - val_accuracy: 1.0000 - val_loss: 0.0107\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 1.0000 - val_loss: 0.0116\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 1.0000 - val_loss: 0.0356\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.5000 - val_loss: 0.4830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x11d5f7b5130>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=4, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1e1a327-2f4c-4aad-b288-367fe1932246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('sign_language_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba6757f9-da06-4af4-809f-65544244b754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5000 - loss: 0.4830\n",
      "Test Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a6f9e20-fd11-458a-ab22-09b4d8f03b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.4830\n",
      "Test Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
